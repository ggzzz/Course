{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3. 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + jnp.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    c = jnp.max(x)\n",
    "    exp_x = jnp.exp(a-c)\n",
    "    sum_exp_x = jnp.sum(exp_x)\n",
    "    y = exp_x / sum_exp_x\n",
    "\n",
    "    return y\n",
    "\n",
    "def softmax_batch(x):\n",
    "    x = x - jnp.max(x, axis=-1, keepdims=True)   # オーバーフロー対策\n",
    "    return jnp.exp(x) / jnp.sum(jnp.exp(x), axis=-1, keepdims=True)\n",
    "\n",
    "# test\n",
    "x = jnp.array([-1.0, 1.0, 2.0])\n",
    "print(jnp.allclose(sigmoid(x), jnp.array([ 0.26894142, 0.73105858, 0.88079708])))\n",
    "\n",
    "a = jnp.array([0.3, 2.9, 4.0])\n",
    "print(jnp.allclose(jnp.sum(softmax(x)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "# 第一次调用会花费几分钟......\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "# 输出各个数据的形状 \n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (60000,) \n",
    "print(x_test.shape) # (10000, 784) \n",
    "print(t_test.shape) # (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist \n",
    "from PIL import Image\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img)) \n",
    "    display(pil_img)\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label) # 5\n",
    "print(img.shape) # (784,)\n",
    "img = img.reshape(28, 28) # 把图像的形状变成原来的尺寸 \n",
    "print(img.shape) # (28, 28)\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = \\\n",
    "        load_mnist(normalize=True, flatten=True, one_hot_label=False) \n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3'] \n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    a1 = jnp.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = jnp.dot(z1, W2) + b2 \n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = jnp.dot(z2, W3) + b3\n",
    "    y = softmax_batch(a3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x, t = get_data() \n",
    "network = init_network()\n",
    "batch_size = 100 # 批数量\n",
    "accuracy_cnt = 0\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4. 神经网络的学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t): \n",
    "    delta = 1e-7\n",
    "    return -jnp.sum(t * jnp.log(y + delta))\n",
    "\n",
    "def cross_entropy_error_batch(y, t): \n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size) \n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * jnp.log(y + 1e-7)) / batch_size\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = jnp.zeros_like(x) # 生成和x形状相同的数组\n",
    "\n",
    "    for idx in range(x.size): \n",
    "        tmp_val = x[idx]\n",
    "        # f(x+h)的计算\n",
    "        x.at[idx].set(tmp_val + h)\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        # f(x-h)的计算\n",
    "        x.at[idx].set(tmp_val - h)\n",
    "        fxh2 = f(x)\n",
    "        grad.at[idx].set((fxh1 - fxh2) / (2*h))\n",
    "        x[idx] = tmp_val # 还原值\n",
    "        \n",
    "    return grad\n",
    "\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 初始化权重 \n",
    "        self.params = {} \n",
    "        self.params['W1'] = weight_init_std * jax.random.normal(key, shape=(input_size, hidden_size))\n",
    "        self.params['b1'] = jnp.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * jax.random.normal(key, shape=(hidden_size, output_size))\n",
    "        self.params['b2'] = jnp.zeros(output_size)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        a1 = jnp.dot(x, W1) + b1 \n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = jnp.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        return y\n",
    "    \n",
    "    # x:输入数据, t:监督数据\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error_batch(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = jnp.argmax(y, axis=1) \n",
    "        t = jnp.argmax(t, axis=1)\n",
    "        accuracy = jnp.sum(y == t) / float(x.shape[0]) \n",
    "        return accuracy\n",
    "    \n",
    "\n",
    "    # x:输入数据, t:监督数据\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1']) \n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1']) \n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2']) \n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        return grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mul got incompatible shapes for broadcasting: (1, 1000), (1, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m t_batch \u001b[39m=\u001b[39m t_train[batch_mask]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# 计算梯度\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m grad \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49mnumerical_gradient(x_batch, t_batch) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# grad = network.gradient(x_batch, t_batch) # 高速版!\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# 更新参数\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mb2\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[1;32m/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m loss_W \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, t)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m grads \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m numerical_gradient(loss_W, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mW1\u001b[39;49m\u001b[39m'\u001b[39;49m]) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m numerical_gradient(loss_W, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m'\u001b[39m]) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m grads[\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m numerical_gradient(loss_W, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m'\u001b[39m]) \n",
      "\u001b[1;32m/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# f(x+h)的计算\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m x\u001b[39m.\u001b[39mat[idx]\u001b[39m.\u001b[39mset(tmp_val \u001b[39m+\u001b[39m h)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m fxh1 \u001b[39m=\u001b[39m f(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# f(x-h)的计算\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m x\u001b[39m.\u001b[39mat[idx]\u001b[39m.\u001b[39mset(tmp_val \u001b[39m-\u001b[39m h)\n",
      "\u001b[1;32m/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumerical_gradient\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     loss_W \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x, t)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     grads \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     grads[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m numerical_gradient(loss_W, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m'\u001b[39m]) \n",
      "\u001b[1;32m/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x, t):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cross_entropy_error_batch(y, t)\n",
      "\u001b[1;32m/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, y\u001b[39m.\u001b[39msize)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m batch_size \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/m/Documents/GitProjects/Course/ML/DL/DL_from_scratch/DL_from_scratch.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum(t \u001b[39m*\u001b[39;49m jnp\u001b[39m.\u001b[39;49mlog(y \u001b[39m+\u001b[39;49m \u001b[39m1e-7\u001b[39;49m)) \u001b[39m/\u001b[39m batch_size\n",
      "File \u001b[0;32m/usr/local/miniconda3/envs/py311/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:269\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    267\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 269\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    270\u001b[0m \u001b[39m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(other) \u001b[39min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/miniconda3/envs/py311/lib/python3.11/site-packages/jax/_src/numpy/ufuncs.py:97\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(x1, x2, \u001b[39m/\u001b[39m):\n\u001b[1;32m     96\u001b[0m   x1, x2 \u001b[39m=\u001b[39m promote_args(numpy_fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, x1, x2)\n\u001b[0;32m---> 97\u001b[0m   \u001b[39mreturn\u001b[39;00m lax_fn(x1, x2) \u001b[39mif\u001b[39;00m x1\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mbool_ \u001b[39melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/miniconda3/envs/py311/lib/python3.11/site-packages/jax/_src/lax/lax.py:1595\u001b[0m, in \u001b[0;36mbroadcasting_shape_rule\u001b[0;34m(name, *avals)\u001b[0m\n\u001b[1;32m   1593\u001b[0m       result_shape\u001b[39m.\u001b[39mappend(non_1s[\u001b[39m0\u001b[39m])\n\u001b[1;32m   1594\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1595\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m got incompatible shapes for broadcasting: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1596\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m,\u001b[39m \u001b[39m\u001b[39mmap\u001b[39m(\u001b[39mtuple\u001b[39m,\u001b[39m \u001b[39mshapes)))\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1598\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(result_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: mul got incompatible shapes for broadcasting: (1, 1000), (1, 3)."
     ]
    }
   ],
   "source": [
    "# mini-batch\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)\n",
    "train_loss_list = []\n",
    "\n",
    "# 超参数\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0] \n",
    "batch_size = 100 \n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num): \n",
    "    # 获取mini-batch\n",
    "    # batch_mask = np.random.choice(train_size, batch_size) \n",
    "    batch_mask = jax.random.choice(key, train_size, shape=(batch_size,), replace=False)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 计算梯度\n",
    "    grad = network.numerical_gradient(x_batch, t_batch) \n",
    "    # grad = network.gradient(x_batch, t_batch) # 高速版!\n",
    "    \n",
    "    # 更新参数\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 记录学习过程\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
